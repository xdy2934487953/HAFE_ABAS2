Causal-HAFE: 基于因果解耦与虚假相关消除的公平性异构图神经网络情感分析
摘要 (Abstract)
方面级情感分析（ABSA）旨在细粒度地识别特定属性的情感极性。尽管现有的图神经网络（GNNs）通过利用句法依存树和注意力机制取得了显著的性能提升，但它们在处理长尾分布（Long-tail Distribution）数据时表现出严重的鲁棒性缺陷。我们研究发现，这种“低资源悖论”的根源在于模型过度拟合了训练数据中的虚假相关（Spurious Correlations）——即高频属性词与特定情感标签之间的统计捷径，而非真实的语义因果逻辑。为了解决这一问题，本文提出了 Causal-HAFE（Causal Heterogeneous Aspect-Frequency Enhanced）框架。该框架首先构建了一个包含句法和语义边缘的异构信息网络（HIN），并基于结构化因果模型（SCM）对 ABSA 任务进行建模。我们引入了后门调整（Backdoor Adjustment） 机制来阻断上下文混淆因子的干扰，并设计了基于解耦信息瓶颈（Disentangled Information Bottleneck, DIB） 的训练目标，强制模型将语义特征与频率偏差特征正交化。此外，我们在推理阶段采用反事实总间接效应（TIE）估算来进一步消除先验偏差。在 SemEval 基准数据集及对抗性测试集 ARTS 上的实验设计表明，Causal-HAFE 能够显著提升模型在低频方面的公平性与鲁棒性。
1. 引言 (Introduction)
1.1 背景与动机
方面级情感分析（ABSA）是自然语言处理中的核心任务之一，其目标是给定一个句子，判断其中特定方面词（Aspect Term）的情感倾向（如“食物”是正面的，“服务”是负面的）。随着深度学习的发展，基于图神经网络（GNN）的方法（如 ASGCN, DualGCN）成为了主流，它们利用句法依存树将方面词与其上下文中的意见词连接起来，有效地解决了长距离依赖问题。
然而，现有的 ABSA 系统面临着一个严峻的公平性挑战：频率偏差（Frequency Bias）。模型在处理训练集中频繁出现的“头部”方面词（如“价格”、“质量”）时表现优异，但在处理罕见的“尾部”方面词时性能急剧下降。传统观点认为这是样本不足导致的欠拟合，但我们的深入分析表明，根本原因在于模型学习到了虚假相关（Spurious Correlations）。例如，如果训练数据中“环境”一词 90% 的情况下伴随着负面评价，GNN 往往会忽略上下文中的否定词，直接依据“环境”这一节点本身做出负面预测。这种基于统计捷径的推理机制，不仅损害了模型的泛化能力，也导致了对长尾实体的不公平对待。
1.2 问题发现
目前的异构图模型（如原始的 HAFE-ABSA）虽然引入了 PMI（点互信息）边来增强语义连接，但这在因果视角下是一把双刃剑。PMI 本质上捕捉的是共现关系，如果两个词（如“电影”和“爆米花”）频繁共现但无因果联系，PMI 边会将这种结构性混淆（Structural Confounding） 编码进图中，反而强化了模型对背景噪声的依赖。此外，标准的交叉熵损失函数无法区分因果特征和环境噪声，导致模型倾向于拟合容易学习的频率特征，而非复杂的句法语义逻辑。
1.3 本文贡献
针对上述问题，我们将 HAFE-ABSA 重构为 Causal-HAFE，主要贡献如下：
因果图重构： 我们构建了 ABSA 的结构化因果模型（SCM），识别了作为混淆因子的“上下文/频率先验”，并利用后门调整（Backdoor Adjustment） 机制设计了去混淆图注意力层（Deconfounded GAT），在图传播过程中切断混淆路径。
特征解耦： 提出了基于解耦信息瓶颈（DIB） 的辅助任务。我们将节点表示分解为“因果语义部分”和“虚假频率部分”，通过最小化互信息约束，迫使模型仅利用因果部分进行情感分类。
反事实推理： 在推理阶段，我们通过计算总间接效应（TIE） 来替代传统的直接预测。通过减去仅由方面词本身触发的自然直接效应（NDE），显式消除了属性词的先验偏差。
2. 相关工作 (Related Work)
2.1 基于图神经网络的 ABSA
早期的 ABSA 方法主要依赖 LSTM 和注意力机制。ASGCN 1 首次引入 GCN 利用依存树结构，随后 DualGCN 2 和 SenticGCN 3 分别引入了语义关联图和常识知识图。然而，这些方法大多基于“同质性假设”或简单的加权聚合，忽略了图结构本身可能编码了数据中的虚假相关性（如高频词汇的枢纽效应）。

2.2 NLP 中的公平性与偏差
NLP 中的公平性研究主要集中在性别、种族等社会属性的去偏（Bias Mitigation）4。近期，研究者开始关注频率偏差和长尾效应。一些工作尝试通过重采样或重加权（Re-weighting）来缓解类别不平衡，但这些方法往往牺牲了头部样本的性能。

2.3 因果推断在 NLP 中的应用
因果推断（Causal Inference）为解决鲁棒性问题提供了新视角。DINER 框架 5 提出了利用反事实推理去除 ABSA 中的上下文混淆。Invariant Risk Minimization (IRM) 6 旨在学习跨环境不变的特征。本文的 Causal-HAFE 结合了异构图的结构优势与因果推断的理论深度，旨在图结构内部实现因果解耦。

3. 问题定义 (Problem Definition)
3.1 任务形式化
给定一个句子 $S = \{w_1, w_2, \dots, w_n\}$ 和一个目标方面词 $A$，ABSA 的任务是预测情感标签 $Y \in \{Pos, Neg, Neu\}$。
3.2 结构化因果模型 (SCM)
我们构建如下 SCM 来描述数据生成过程：
$C$ (Confounder)：未观测的混淆因子（如词频分布、领域背景）。
$A$ (Aspect)：方面词。
$R$ (Context)：上下文表示。
$Y$ (Sentiment)：情感标签。
在传统的图模型中，存在后门路径 $A \leftarrow C \rightarrow Y$ 和 $R \leftarrow C \rightarrow Y$。模型容易学习到 $C \rightarrow Y$ 的虚假关联。我们的目标是学习真实的因果路径 $(A, R) \rightarrow Y$，即估计 $P(Y | do(A), do(R))$。
4. 方法论 (Methodology)
Causal-HAFE 框架由三个核心模块组成：基于后门调整的异构图构建、解耦信息瓶颈训练、以及反事实推理。
4.1 模块一：基于后门调整的去混淆图构建
我们首先构建包含句法边和语义边的异构图。为了消除图中潜藏的混淆影响（例如，某些边仅因为高频共现而存在），我们在图注意力（GAT）层引入后门调整。
传统的 GAT 计算注意力系数 $\alpha_{ij} \propto \exp(e_{ij})$，这容易受混淆因子 $C$ 影响。我们提出的 Deconfounded GAT 计算干预后的注意力：


$$\alpha_{ij}^{causal} \approx \sum_{k=1}^K P(c_k) \cdot \text{Attention}(h_i, h_j | c_k)$$

其中 $c_k$ 是通过聚类得到的上下文混淆因子原型（Context Prototypes）。通过对所有可能的混淆背景进行加权求和，模型被迫关注那些在不同上下文中都稳定的连接（即真实语义依赖），从而“洗去”特定背景下的虚假强相关。
4.2 模块二：解耦信息瓶颈 (Disentangled Information Bottleneck, DIB)
为了确保学到的节点表示 $Z$ 不包含频率偏差，我们将 $Z$ 分解为两个独立子空间：因果表示 $Z_c$ 和 虚假表示 $Z_s$。
优化目标包含以下四部分：
任务损失：使用 $Z_c$ 预测情感标签 $Y$。

$$\mathcal{L}_{task} = \text{CrossEntropy}(\text{Classifier}(Z_c), Y)$$
解耦约束：最小化 $Z_c$ 和 $Z_s$ 之间的互信息，确保语义特征不泄露到虚假特征中。

$$\mathcal{L}_{indep} = I(Z_c; Z_s)$$
偏差拟合：强制 $Z_s$ 预测方面词的频率阶（Frequency Bucket）$F$。这确保 $Z_s$ 确实捕获了频率偏差信息。

$$\mathcal{L}_{bias} = \text{CrossEntropy}(\text{Discriminator}(Z_s), F)$$
信息瓶颈：最小化 $Z_c$ 与输入 $X$ 的互信息，去除冗余噪声。
总损失函数为：$\mathcal{L} = \mathcal{L}_{task} + \lambda_1 \mathcal{L}_{indep} + \lambda_2 \mathcal{L}_{bias} + \lambda_3 \mathcal{L}_{IB}$。
4.3 模块三：基于 TIE 的反事实推理
在推理阶段，我们不仅依赖训练好的模型，还进行反事实纠偏。
我们将最终的预测分数定义为 总间接效应 (Total Indirect Effect, TIE)：


$$\text{TIE} = \text{Logits}(A, R) - \text{Logits}(A, \emptyset)$$
$\text{Logits}(A, R)$：模型在完整输入下的预测（包含偏差）。
$\text{Logits}(A, \emptyset)$：模型在屏蔽上下文 $R$ 后的预测。这代表了仅凭方面词 $A$（及其频率先验）产生的自然直接效应 (NDE)。
通过减去 NDE，我们消除了模型因看到“高频正面词”而直接产生的盲目预测，迫使最终结果必须由上下文 $R$ 的证据支持。
5. 实验设计 (Experimental Design)
为了验证 Causal-HAFE 的有效性，特别是其在公平性和鲁棒性方面的优势，我们设计了以下实验。
5.1 数据集
标准数据集： SemEval 2014 (Laptop, Restaurant) 和 SemEval 2016 (Restaurant)。用于评估基础准确率。
鲁棒性/偏差数据集： ARTS (Aspect Robustness Test Set) 7。该数据集通过增加干扰项、反转非目标情感等方式生成对抗样本，专门用于测试模型是否依赖虚假相关。


长尾分割： 将测试集按方面词频率分为 Head（高频）、Medium（中频）、Tail（低频）三组，分别评估。
5.2 基准模型 (Baselines)
RoBERTa-SPC： 强大的预训练语言模型基线。
ASGCN / DualGCN： 代表性的图神经网络基线（存在同质化和偏差问题）。
DINER： 目前 SOTA 的因果去偏 ABSA 框架（主要用于对比去偏效果）。
HAFE (w/o Causal)： 本文模型的消融版本，去除因果模块，仅保留异构图结构。
5.3 评估指标
Macro-F1 & Accuracy： 总体性能指标。
Freq-DP (Frequency-based Demographic Parity)： 定义为头部方面词和尾部方面词之间错误率（Error Rate）的差异。该值越低，表示模型对低频词越公平。

$$\Delta_{DP} = |Err(Head) - Err(Tail)|$$
ARTS Robustness Score： 在 ARTS 对抗数据集上的准确率。这是衡量模型是否真正理解语义而非依赖捷径的关键指标。
5.4 预期分析 (Hypothesis)
我们预期 Causal-HAFE 在总体 F1 上与 RoBERTa/DualGCN 持平或略高，但在 Tail 分组的 F1 值上将显著优于基线（预计提升 10-15%）。
在 ARTS 数据集上，基线模型的性能通常会下降 20-30%，我们预期 Causal-HAFE 的下降幅度显著更小，证明其学到了鲁棒的因果特征。
通过 t-SNE 可视化 $Z_c$ 和 $Z_s$，我们预期看到 $Z_c$ 按情感极性聚类（与频率无关），而 $Z_s$ 按频率高低聚类，从而定性验证解耦的成功。
6. 结论 (Conclusion)
本文通过因果推断的视角重新审视了方面级情感分析中的频率偏差问题。我们指出，传统的图神经网络容易将数据中的统计捷径编码为虚假相关。Causal-HAFE 框架通过后门调整重构图注意力机制，利用解耦信息瓶颈分离因果与虚假特征，并采用反事实推理消除先验偏差。这种方法论的转变——从拟合相关性到发现因果性——不仅解决了长尾方面的预测难题，也为构建更加可信、公平的 NLP 系统提供了通用的理论框架。未来的工作将探索将此框架扩展到多模态情感分析及大语言模型的指令微调中。
